task_attributes:
    vqa:
        datasets:
        - textvqa
        dataset_size_proportional_sampling: true
        dataset_attributes:
            textvqa:
                data_root_dir: ../data
                image_depth_first: false
                slow_read: false
                image_features:
                    train:
                    - open_images/detectron_fix_100/fc6/train,open_images/resnet152/train
                    val:
                    - open_images/detectron_fix_100/fc6/val,open_images/resnet152/val
                    test:
                    - open_images/detectron_fix_100/fc6/test,open_images/resnet152/test
                imdb_files:
                    train:
                    - imdb/imdb_textvqa_train.npy
                    val:
                    - imdb/imdb_textvqa_val.npy
                    test:
                    - imdb/imdb_textvqa_test.npy
                features_max_len: 137
                question_max_len: 14
                context_max_len: 50
                processors:
                  text_processor:
                    type: glove
                    params:
                      max_length: 14
                      vocab:
                        type: intersected
                        embedding_name: glove.6B.300d
                        vocab_file: vocabulary_vqa_100k.txt
                  answer_processor:
                    type: vqa_answer
                    params:
                      vocab_file: answers_textvqa_8k.txt
                      preprocessor:
                        type: simple_word
                        params: {}
                  context_processor:
                    type: fasttext
                    params:
                      max_length: 50
                      model_file: .vector_cache/wiki.en.bin
                metrics:
                - vqa_accuracy
                loss: logit_bce
                return_info: true
training_parameters:
    monitored_metric: textvqa_vqa_accuracy
    metric_minimize: false
