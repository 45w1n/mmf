task_attributes:
  vqa:
    datasets: vqa2
    dataset_size_proportional_sampling: true
    dataset_attributes:
      vqa2:
        data_root_dir: /private/home/asg/pythia/data
        image_depth_first: false
        image_fast_reader: false
        image_feat_test:
        - /checkpoint/asg/old_checkpoint02/data/detectron_fix_100/fc6/vqa/test2015
        image_feat_train:
        - /checkpoint/asg/old_checkpoint02/data/detectron_fix_100/fc6/vqa/train2014
        - /checkpoint/asg/old_checkpoint02/data/detectron_fix_100/fc6/vqa/val2014
        image_feat_val:
        - /checkpoint/asg/old_checkpoint02/data/detectron_fix_100/fc6/vqa/val2014
        image_max_loc: 100
        imdb_file_test:
        - imdb/imdb_test2015.npy
        imdb_file_train:
        - imdb/imdb_train2014.npy
        - imdb/imdb_val2014.npy
        imdb_file_val:
        - imdb/imdb_minival2014.npy
        question_max_len: 14
        vocab_answer_file: answers_vqa.txt
        vocab_question_file: vocabulary_vqa.txt
        enforce_slow_reader: true
        metrics: vqa_accuracy
        context_max_len: 50
        loss: logit_bce
        copy_included: false
        copy_type: soft
exp_name: baseline
model_attributes:
  ban:
    text_embedding:
      num_hidden: 1280
      vocab_size: 1280
      emb_size: 300
      num_layers: 1
      dropout: 0.0
      bidirectional: False
      rnn_type: 'GRU'
    bilinear_attention:
      bc_net:
        k: 1
        dropout: [0.2, 0.5]
        h_out:
      fc_net:
        dims: 600
        activation: 
        dropout: 0.2
      gamma: 4
      visual_feat_dim: 2048
    classifier:
      hidden_size: 600
      out_dim: 3129
      dropout: 0.5
optimizer_attributes:
  type: Adamax
  params:
    eps: 1.0e-08
    lr: 0.01
    weight_decay: 0
training_parameters:
  clip_norm_mode: all
  clip_gradients: true
  lr_ratio: 0.1
  lr_scheduler: true
  lr_steps:
  - 15000
  - 18000
  - 20000
  - 21000
  max_grad_l2_norm: 0.25
  max_iterations: 22000
  log_interval: 100
  snapshot_interval: 6000
  wu_factor: 0.2
  wu_iters: 1000
  patience: 4000
  batch_size: 128
  num_workers: 7
  task_size_proportional_sampling: true
  run_type: train+inference
  monitored_metric: vqa2_vqa_accuracy
  metric_minimize: false
  text_vocab:
    type: intersected
    embedding_name: glove.6B.300d
    vocab_file: /private/home/asg/pythia/data/vocabulary_vqa.txt
